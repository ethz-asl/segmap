#!/usr/bin/env python
from __future__ import print_function
import numpy as np
import sys
import os

import ensure_segmappy_is_installed
from segmappy import Config
from segmappy import Dataset
from segmappy import Generator
from segmappy.tools.classifiertools import get_default_dataset, get_default_preprocessor
from segmappy.tools.roccurve import get_roc_pairs, get_roc_curve

# read config file
configfile = "default_training.ini"

config = Config(configfile)

# add command line arguments to config
import argparse

parser = argparse.ArgumentParser()
parser.add_argument("--log")
#parser.add_argument("--debug", action="store_true")
parser.add_argument("--checkpoints", type=int, default=1)
parser.add_argument("--keep-best", action="store_true")
parser.add_argument("--roc", action="store_true")
args = parser.parse_args()
config.log_name = args.log
#config.debug = args.debug
config.checkpoints = args.checkpoints
config.keep_best = args.keep_best
config.roc = args.roc

# create or empty the model folder
if not os.path.exists(config.cnn_model_folder):
    os.makedirs(config.cnn_model_folder)
else:
    import glob

    model_files = glob.glob(os.path.join(config.cnn_model_folder, "*"))
    for model_file in model_files:
        os.remove(model_file)

# load preprocessor
preprocessor = get_default_preprocessor(config)

segments = []
segments_color = []
segments_class = []
classes = np.array([], dtype=np.int)
n_classes = 0
duplicate_classes = np.array([], dtype=np.int)
max_duplicate_class = 0
duplicate_ids = np.array([], dtype=np.int)

runs = config.cnn_train_folders.split(",")
for run in runs:
    dataset = get_default_dataset(config, run)

    run_segments, _, run_classes, run_n_classes, _, _, _ = dataset.load(
        preprocessor=preprocessor
    )
    run_duplicate_classes = dataset.duplicate_classes
    run_duplicate_ids = dataset.duplicate_ids

    run_classes += n_classes
    run_duplicate_classes += max_duplicate_class

    segments += run_segments
    segments_color += dataset.segments_color
    segments_class += dataset.segments_class
    classes = np.concatenate((classes, run_classes), axis=0)
    n_classes += run_n_classes
    duplicate_classes = np.concatenate(
        (duplicate_classes, run_duplicate_classes), axis=0
    )
    duplicate_ids = np.concatenate((duplicate_ids, run_duplicate_ids), axis=0)

    max_duplicate_class = np.max(duplicate_classes) + 1

'''if config.debug:
    import json

    # empty or create the debug folder
    if os.path.isdir(config.debug_path):
        import glob

        debug_files = glob.glob(os.path.join(config.debug_path, "*.json"))
        for debug_file in debug_files:
            os.remove(debug_file)
    else:
        os.makedirs(config.debug_path)

    # store loss information
    epoch_log = []
    train_loss_log = []
    train_loss_c_log = []
    train_loss_r_log = []
    train_accuracy_log = []
    test_loss_log = []
    test_loss_c_log = []
    test_loss_r_log = []
    test_accuracy_log = []

    # store segment centers for the current run
    centers = []
    for cls in range(n_classes):
        class_ids = np.where(classes == cls)[0]
        last_id = class_ids[np.argmax(duplicate_ids[class_ids])]
        centers.append(np.mean(segments[last_id], axis=0).tolist())

    with open(os.path.join(config.debug_path, "centers.json"), "w") as fp:
        json.dump(centers, fp)

    # info for sequence prediction visualization
    pred = [0] * (np.max(duplicate_classes) + 1)
    duplicate_ids_norm = np.zeros(duplicate_ids.shape, dtype=np.int)
    for duplicate_class in np.unique(duplicate_classes):
        segment_ids = np.where(duplicate_classes == duplicate_class)[0]
        pred[duplicate_class] = [None] * segment_ids.size

        for i, segment_id in enumerate(segment_ids):
            duplicate_ids_norm[segment_id] = i

    def debug_write_pred(segment_id, segment_probs, train):
        top5_classes = np.argsort(segment_probs)[::-1]
        top5_classes = top5_classes[:5]
        top5_prob = segment_probs[top5_classes]

        segment_class = classes[segment_id]
        segment_prob = segment_probs[segment_class]

        info = [
            int(train),
            int(segment_class),
            float(segment_prob),
            top5_classes.tolist(),
            top5_prob.tolist(),
        ]

        duplicate_class = duplicate_classes[segment_id]
        duplicate_id = duplicate_ids_norm[segment_id]

        pred[duplicate_class][duplicate_id] = info'''

# split so that the test set contains entire sequences
train_fold = np.ones(classes.shape, dtype=np.int)
for c in np.unique(classes):
    dup_classes = duplicate_classes[classes == c]
    unique_dup_classes = np.unique(dup_classes)

    # choose for train the sequence with the largest last segment
    dup_sizes = []
    for dup_class in unique_dup_classes:
        dup_ids = np.where(dup_class == duplicate_classes)[0]
        last_id = np.max(dup_ids)
        dup_sizes.append(segments[last_id].shape[0])

    dup_keep = np.argmax(dup_sizes)

    # randomly distribute the others
    for i, dup_class in enumerate(unique_dup_classes):
        if i != dup_keep:
            if np.random.random() < config.test_size:
                train_fold[duplicate_classes == dup_class] = 0

train_ids = np.where(train_fold == 1)[0]
test_ids = np.where(train_fold == 0)[0]

# initialize preprocessor
preprocessor.init_segments(segments, segments_color, segments_class, classes, train_ids=train_ids)

# save scaler mean in a csv
if config.remove_mean:
    scaler_path = os.path.join(config.cnn_model_folder, "scaler_mean.csv")
    with open(scaler_path, "w") as fp:
        for i in preprocessor._scaler.mean_:
            fp.write(str(i) + "\n")

# save the scaler as well using pickle
if config.remove_mean or config.remove_std:
    scaler_path = os.path.join(config.cnn_model_folder, "scaler.pkl")
    preprocessor.save_scaler(scaler_path)

# initialize segment batch generators
gen_train = Generator(
    preprocessor,
    train_ids,
    n_classes,
    train=True,
    batch_size=config.batch_size,
    shuffle=True,
)
gen_test = Generator(
    preprocessor,
    test_ids,
    n_classes,
    train=False,
    batch_size=config.batch_size,
    shuffle=True,
)

print("Training with %d segments" % gen_train.n_segments)
print("Testing with %d segments" % gen_test.n_segments)

import tensorflow as tf
import segmappy.models.model_pointnet2 as pointnet2
import segmappy.tools.tf_util as tf_util

tf.reset_default_graph()

NUM_POINT = 1024
BASE_LEARNING_RATE = 0.001
DECAY_STEP = 200000
DECAY_RATE = 0.7
BN_INIT_DECAY = 0.5
BN_DECAY_DECAY_RATE = 0.5
BN_DECAY_DECAY_STEP = float(DECAY_STEP)
BN_DECAY_CLIP = 0.99

def get_learning_rate(batch):
    #learning_rate = tf.train.exponential_decay(
    #                    BASE_LEARNING_RATE,  # Base learning rate.
    #                    batch * config.batch_size,  # Current index into the dataset.
    #                    DECAY_STEP,          # Decay step.
    #                    DECAY_RATE,          # Decay rate.
    #                    staircase=True)
    #learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!
    learning_rate = tf.constant(BASE_LEARNING_RATE)
    return learning_rate

def get_bn_decay(batch):
    #bn_momentum = tf.train.exponential_decay(
    #                  BN_INIT_DECAY,
    #                  batch * config.batch_size,
    #                  BN_DECAY_DECAY_STEP,
    #                  BN_DECAY_DECAY_RATE,
    #                  staircase=True)
    #bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)
    bn_decay = tf.constant(0.9)
    return bn_decay

pointclouds_pl, labels_pl = pointnet2.placeholder_inputs(
    config.batch_size, NUM_POINT, n_classes)
is_training_pl = tf.placeholder(tf.bool, shape=())

batch = tf.get_variable('batch', [],
    initializer=tf.constant_initializer(0), trainable=False)
bn_decay = get_bn_decay(batch)
tf.summary.scalar('bn_decay', bn_decay)

# Get model and loss
pred, end_points = pointnet2.get_model(
    pointclouds_pl, is_training_pl, n_classes, bn_decay=bn_decay)
pointnet2.get_loss(pred, labels_pl, end_points)
losses = tf.get_collection('losses')
total_loss = tf.add_n(losses, name='total_loss')
tf.summary.scalar('total_loss', total_loss)
for l in losses + [total_loss]:
    tf.summary.scalar(l.op.name, l)

correct = tf.equal(tf.argmax(pred, 1), tf.argmax(labels_pl, 1))
accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(config.batch_size)
tf.summary.scalar('accuracy', accuracy)

learning_rate = get_learning_rate(batch)
tf.summary.scalar('learning_rate', learning_rate)
optimizer = tf.train.AdamOptimizer(learning_rate)
train_op = optimizer.minimize(total_loss, global_step=batch)

saver = tf.train.Saver(max_to_keep=config.checkpoints)
merged = tf.summary.merge_all()

tf_config = tf.ConfigProto()
tf_config.gpu_options.allow_growth = True
tf_config.allow_soft_placement = True
tf_config.log_device_placement = False

with tf.Session(config=tf_config) as sess:
    # tensorboard statistics
    if config.log_name:
        train_writer = tf.summary.FileWriter(
            os.path.join(config.log_path, config.log_name, "train"), sess.graph
        )
        test_writer = tf.summary.FileWriter(
            os.path.join(config.log_path, config.log_name, "test")
        )

    # initialize all tf variables
    tf.global_variables_initializer().run()

    # remember best epoch accuracy
    if config.keep_best:
        best_accuracy = 0

    ops = {'pointclouds_pl': pointclouds_pl,
           'labels_pl': labels_pl,
           'is_training_pl': is_training_pl,
           'pred': pred,
           'loss': total_loss,
           'train_op': train_op,
           'merged': merged,
           'step': batch,
           'end_points': end_points}

    # sequence of train and test batches
    batches = np.array([1] * gen_train.n_batches + [0] * gen_test.n_batches)
    for epoch in range(0, config.n_epochs):
        train_loss = 0
        train_accuracy = 0
        train_step = 0

        test_loss = 0
        test_accuracy = 0
        test_step = 0

        np.random.shuffle(batches)

        console_output_size = 0
        for step, train in enumerate(batches):
            if train:
                batch_segments, batch_classes = gen_train.next()
                # TODO(smauq): Fix variable batch size
                if batch_segments.shape[0] != config.batch_size:
                    continue

                feed_dict = {ops['pointclouds_pl']: batch_segments,
                             ops['labels_pl']: batch_classes,
                             ops['is_training_pl']: True}

                summary, step, _, batch_loss, batch_pred = sess.run([ops['merged'],
                    ops['step'], ops['train_op'], ops['loss'], ops['pred']],
                    feed_dict=feed_dict)

                #if config.debug:
                #    for i, segment_id in enumerate(gen_train.batch_ids):
                #        debug_write_pred(segment_id, batch_prob[i], train)

                if config.log_name:
                    train_writer.add_summary(summary, step)

                correct = np.sum(
                    np.argmax(batch_pred, axis=1) == np.argmax(batch_classes, axis=1))

                train_loss += batch_loss
                train_accuracy += correct / float(batch_segments.shape[0])
                train_step += 1
            else:
                batch_segments, batch_classes = gen_test.next()
                # TODO(smauq): Fix variable batch size
                if batch_segments.shape[0] != config.batch_size:
                    continue

                # calculate test loss and accuracy
                feed_dict = {ops['pointclouds_pl']: batch_segments,
                             ops['labels_pl']: batch_classes,
                             ops['is_training_pl']: False}

                summary, step, batch_loss, batch_pred = sess.run([ops['merged'],
                    ops['step'], ops['loss'], ops['pred']], feed_dict=feed_dict)

                #if config.debug:
                #    for i, segment_id in enumerate(gen_test.batch_ids):
                #        debug_write_pred(segment_id, batch_prob[i], train)

                if config.log_name:
                    test_writer.add_summary(summary, step)

                correct = np.sum(
                    np.argmax(batch_pred, axis=1) == np.argmax(batch_classes, axis=1))

                test_loss += batch_loss
                test_accuracy += correct / float(batch_segments.shape[0])
                test_step += 1

            # print results
            sys.stdout.write("\b" * console_output_size)

            console_output = "epoch %2d " % epoch

            if train_step:
                console_output += "loss %.4f acc %.2f " % (
                    train_loss / train_step,
                    train_accuracy / train_step * 100
                )

            if test_step:
                console_output += "v_loss %.4f v_acc %.2f" % (
                    test_loss / test_step,
                    test_accuracy / test_step * 100
                )

            console_output_size = len(console_output)

            sys.stdout.write(console_output)
            sys.stdout.flush()

        # dump prediction values and loss
        '''if config.debug:
            epoch_debug_file = os.path.join(config.debug_path, "%d.json" % epoch)
            with open(epoch_debug_file, "w") as fp:
                json.dump(pred, fp)

            epoch_log.append(epoch)
            train_loss_log.append(train_loss / train_step)
            train_loss_c_log.append(train_loss_c / train_step)
            train_loss_r_log.append(train_loss_r / train_step)
            train_accuracy_log.append(train_accuracy / train_step * 100)
            test_loss_log.append(test_loss / test_step)
            test_loss_c_log.append(test_loss_c / test_step)
            test_loss_r_log.append(test_loss_r / test_step)
            test_accuracy_log.append(test_accuracy / test_step * 100)

            with open(os.path.join(config.debug_path, "loss.json"), "w") as fp:
                json.dump(
                    {
                        "epoch": epoch_log,
                        "train_loss": train_loss_log,
                        "train_loss_c": train_loss_c_log,
                        "train_loss_r": train_loss_r_log,
                        "train_accuracy": train_accuracy_log,
                        "test_loss": test_loss_log,
                        "test_loss_c": test_loss_c_log,
                        "test_loss_r": test_loss_r_log,
                        "test_accuracy": test_accuracy_log,
                    },
                    fp,
                )'''

        # flush tensorboard log
        if config.log_name:
            train_writer.flush()
            test_writer.flush()

        # save epoch model
        if not config.keep_best or test_accuracy > best_accuracy:
            if config.checkpoints > 1:
                model_name = "model-%d.ckpt" % step
            else:
                model_name = "model.ckpt"

            saver.save(sess, os.path.join(config.cnn_model_folder, model_name))
            tf.train.write_graph(
                sess.graph.as_graph_def(), config.cnn_model_folder, "graph.pb"
            )

        print()
