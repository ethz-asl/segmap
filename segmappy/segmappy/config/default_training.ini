[general]
# Database folder
# If no base_dir is given, the default base_dir will be used instead
#base_dir = ...
cnn_train_folders = dataset18,dataset20
cnn_test_folder = dataset27
semantics_train_folder = dataset18

# Combine sequences based on merge events triggered in segmatch
use_merges = true

# Size of the merged sequence compared to the last element in the merged
# sequence to keep matches containing the merged sequence
keep_match_thresh = 0.3

# Combine the views based on the segmatch matches
use_matches = true

# Discard classes of segments that are smaller than min_class_size
min_class_size = 2

# The relative size of a segment compared to the last segment in the sequence
# so that it is still considered relevant and kept
require_relevance = 0.05

# The number of points that must be different so that two segments are
# considered different. Similar segments are removed in chronological order
require_diff_points = 0

[augment]
# Generate new samples by randomly rotating each sample by
# [-augment_angle, augment_angle] degrees.
augment_angle = 180

# Augment by randomly removing a percentage of points from each sample
augment_remove_random_min = 0.0
augment_remove_random_max = 0.1
augment_remove_plane_min = 0.0
augment_remove_plane_max = 0.5

# Augment by randomly jittering the segment after centering
augment_jitter = 0.0

[normalize]
# Align the segments (robot/eigen/none)
align = eigen

# Which type of scaling to use
#     - fixed: use a fixed scale
#     - aspect: scale, but maintain aspect ratio
#     - fit: scale each dimenstion indipendently
scale_method = fit

# How to center the segment
#     - mean: based on the segments mean, some point will be out of bounds
#     - min_max: centers based on the min and max of each dimension
#     - none: no centering
center_method = mean

# Size of the voxel parallelepiped in meters
scale_x = 8
scale_y = 8
scale_z = 4

# Number of voxels in the rectangular parallelepiped into
# which to normalize each segment
voxels_x = 32
voxels_y = 32
voxels_z = 16

# Remove the mean and std
remove_mean = false
remove_std = false

[train]
# Folder into which to save the model after training
# If no model_base_dir is given, the default model_base_dir will be used instead
#model_base_dir = ...
cnn_model_folder = segmap64
semantics_model_folder = segmap64_semantics

# Percentage of match sequences to put in the test set
test_size = 0.3

# Number of epochs to train for
n_epochs = 256

# Batch size
batch_size = 64

# Root path to save tensorboard logs
log_path = /tmp/segmap/tensorboard/

# Directory where to save debug outputs
debug_path = /tmp/segmap/debug
